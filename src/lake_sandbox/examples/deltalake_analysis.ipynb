{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeltaLake Data Analysis with DuckDB\n",
    "\n",
    "This notebook demonstrates how to analyze the timeseries data stored in DeltaLake format using DuckDB and create visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DeltaLake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and install delta extension\n",
    "conn = duckdb.connect()\n",
    "conn.execute(\"INSTALL delta\")\n",
    "conn.execute(\"LOAD delta\")\n",
    "\n",
    "print(\"Connected to DuckDB with Delta extension loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query DeltaLake Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define path to delta tables\ndelta_dir = \"../../../output/timeseries-delta\"\ndelta_path = Path(delta_dir).absolute()\n\nprint(f\"Delta directory: {delta_path}\")\nprint(f\"Directory exists: {delta_path.exists()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query all parcel data from DeltaLake tables\n# Note: We need to query each chunk individually since wildcard patterns don't work with delta_scan\n\n# Find all parcel chunk directories\nchunk_dirs = list(delta_path.glob(\"parcel_chunk=*\"))\nprint(f\"Found {len(chunk_dirs)} parcel chunks to query\")\n\n# Query each chunk and combine\ndataframes = []\nfor chunk_dir in sorted(chunk_dirs):\n    try:\n        query = f\"\"\"\n        SELECT \n            parcel_id,\n            date,\n            utm_tile,\n            ndvi,\n            evi,\n            savi,\n            cloud_cover,\n            observation_quality\n        FROM delta_scan('{chunk_dir}')\n        \"\"\"\n        chunk_df = conn.execute(query).df()\n        if not chunk_df.empty:\n            dataframes.append(chunk_df)\n            print(f\"Loaded {len(chunk_df):,} records from {chunk_dir.name}\")\n    except Exception as e:\n        print(f\"Warning: Failed to read {chunk_dir.name}: {e}\")\n        continue\n\n# Combine all dataframes\ndf = pd.concat(dataframes, ignore_index=True)\ndf = df.sort_values(['parcel_id', 'date']).reset_index(drop=True)\n\nprint(f\"Total loaded: {len(df):,} observations for {df['parcel_id'].nunique():,} parcels\")\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Total observations: {len(df):,}\")\n",
    "print(f\"Unique parcels: {df['parcel_id'].nunique():,}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"UTM tiles: {df['utm_tile'].unique()}\")\n",
    "print(f\"Observation dates: {df['date'].nunique()}\")\n",
    "\n",
    "# Data types and missing values\n",
    "print(\"\\n=== DATA INFO ===\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"=== STATISTICAL SUMMARY ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vegetation Index Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plots for vegetation indices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# NDVI distribution\n",
    "axes[0, 0].hist(df[\"ndvi\"], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0, 0].set_title(\"NDVI Distribution\", fontsize=14)\n",
    "axes[0, 0].set_xlabel(\"NDVI\")\n",
    "axes[0, 0].set_ylabel(\"Frequency\")\n",
    "axes[0, 0].axvline(df[\"ndvi\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"ndvi\"].mean():.3f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# EVI distribution\n",
    "axes[0, 1].hist(df[\"evi\"], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0, 1].set_title(\"EVI Distribution\", fontsize=14)\n",
    "axes[0, 1].set_xlabel(\"EVI\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "axes[0, 1].axvline(df[\"evi\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"evi\"].mean():.3f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# SAVI distribution\n",
    "axes[1, 0].hist(df[\"savi\"], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1, 0].set_title(\"SAVI Distribution\", fontsize=14)\n",
    "axes[1, 0].set_xlabel(\"SAVI\")\n",
    "axes[1, 0].set_ylabel(\"Frequency\")\n",
    "axes[1, 0].axvline(df[\"savi\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"savi\"].mean():.3f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Cloud cover distribution\n",
    "axes[1, 1].hist(df[\"cloud_cover\"], bins=30, alpha=0.7, color='gray', edgecolor='black')\n",
    "axes[1, 1].set_title(\"Cloud Cover Distribution\", fontsize=14)\n",
    "axes[1, 1].set_xlabel(\"Cloud Cover (%)\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "axes[1, 1].axvline(df[\"cloud_cover\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"cloud_cover\"].mean():.1f}%')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_cols = [\"ndvi\", \"evi\", \"savi\", \"cloud_cover\", \"observation_quality\"]\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title(\"Correlation Matrix: Vegetation Indices and Environmental Factors\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sample a few parcels for time series visualization\n",
    "sample_parcels = df['parcel_id'].unique()[:15]\n",
    "sample_data = df[df['parcel_id'].isin(sample_parcels)]\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, parcel_id in enumerate(sample_parcels):\n",
    "    parcel_data = sample_data[sample_data['parcel_id'] == parcel_id].sort_values('date')\n",
    "    plt.plot(parcel_data['date'], parcel_data['ndvi'], \n",
    "             marker='o', markersize=4, alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.title(f\"NDVI Time Series for {len(sample_parcels)} Sample Parcels\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"NDVI\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month information\n",
    "df['month'] = df['date'].dt.month\n",
    "df['month_name'] = df['date'].dt.strftime('%B')\n",
    "\n",
    "# Calculate monthly averages\n",
    "monthly_stats = df.groupby(['month', 'month_name']).agg({\n",
    "    'ndvi': ['mean', 'std'],\n",
    "    'evi': ['mean', 'std'],\n",
    "    'savi': ['mean', 'std'],\n",
    "    'cloud_cover': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "print(\"Monthly Statistics:\")\n",
    "print(monthly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot monthly trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "monthly_means = df.groupby('month_name')[['ndvi', 'evi', 'savi', 'cloud_cover']].mean()\n",
    "months_order = df.sort_values('month')['month_name'].unique()\n",
    "monthly_means = monthly_means.reindex(months_order)\n",
    "\n",
    "# NDVI trend\n",
    "axes[0, 0].plot(months_order, monthly_means['ndvi'], marker='o', linewidth=3, markersize=8, color='green')\n",
    "axes[0, 0].set_title(\"Monthly Average NDVI\", fontsize=14)\n",
    "axes[0, 0].set_ylabel(\"NDVI\")\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# EVI trend\n",
    "axes[0, 1].plot(months_order, monthly_means['evi'], marker='o', linewidth=3, markersize=8, color='blue')\n",
    "axes[0, 1].set_title(\"Monthly Average EVI\", fontsize=14)\n",
    "axes[0, 1].set_ylabel(\"EVI\")\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# SAVI trend\n",
    "axes[1, 0].plot(months_order, monthly_means['savi'], marker='o', linewidth=3, markersize=8, color='orange')\n",
    "axes[1, 0].set_title(\"Monthly Average SAVI\", fontsize=14)\n",
    "axes[1, 0].set_ylabel(\"SAVI\")\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cloud cover trend\n",
    "axes[1, 1].plot(months_order, monthly_means['cloud_cover'], marker='o', linewidth=3, markersize=8, color='gray')\n",
    "axes[1, 1].set_title(\"Monthly Average Cloud Cover\", fontsize=14)\n",
    "axes[1, 1].set_ylabel(\"Cloud Cover (%)\")\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTM Tile Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare vegetation indices between UTM tiles\n",
    "tile_comparison = df.groupby('utm_tile').agg({\n",
    "    'ndvi': ['mean', 'std', 'count'],\n",
    "    'evi': ['mean', 'std'],\n",
    "    'savi': ['mean', 'std'],\n",
    "    'cloud_cover': ['mean', 'std'],\n",
    "    'parcel_id': 'nunique'\n",
    "}).round(4)\n",
    "\n",
    "print(\"UTM Tile Comparison:\")\n",
    "print(tile_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots comparing tiles\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# NDVI by tile\n",
    "df.boxplot(column='ndvi', by='utm_tile', ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"NDVI Distribution by UTM Tile\")\n",
    "axes[0, 0].set_xlabel(\"UTM Tile\")\n",
    "axes[0, 0].set_ylabel(\"NDVI\")\n",
    "\n",
    "# EVI by tile\n",
    "df.boxplot(column='evi', by='utm_tile', ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"EVI Distribution by UTM Tile\")\n",
    "axes[0, 1].set_xlabel(\"UTM Tile\")\n",
    "axes[0, 1].set_ylabel(\"EVI\")\n",
    "\n",
    "# Cloud cover by tile\n",
    "df.boxplot(column='cloud_cover', by='utm_tile', ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Cloud Cover Distribution by UTM Tile\")\n",
    "axes[1, 0].set_xlabel(\"UTM Tile\")\n",
    "axes[1, 0].set_ylabel(\"Cloud Cover (%)\")\n",
    "\n",
    "# Observation quality by tile\n",
    "df.boxplot(column='observation_quality', by='utm_tile', ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Observation Quality by UTM Tile\")\n",
    "axes[1, 1].set_xlabel(\"UTM Tile\")\n",
    "axes[1, 1].set_ylabel(\"Observation Quality\")\n",
    "\n",
    "plt.suptitle(\"\")  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Queries with DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Find parcels with highest NDVI growth\n# Note: Using the already loaded dataframe instead of direct DuckDB query for simplicity\n\n# Calculate NDVI growth per parcel\nparcel_stats = df.groupby(['parcel_id', 'utm_tile']).agg({\n    'ndvi': ['min', 'max', 'mean', 'count']\n}).round(4)\n\n# Flatten column names\nparcel_stats.columns = ['min_ndvi', 'max_ndvi', 'avg_ndvi', 'observations']\nparcel_stats = parcel_stats.reset_index()\n\n# Calculate NDVI growth\nparcel_stats['ndvi_growth'] = parcel_stats['max_ndvi'] - parcel_stats['min_ndvi']\n\n# Filter parcels with at least 10 observations and sort by growth\nhigh_growth = parcel_stats[parcel_stats['observations'] >= 10].sort_values('ndvi_growth', ascending=False).head(10)\n\nprint(\"Top 10 Parcels with Highest NDVI Growth:\")\nprint(high_growth)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Monthly aggregations using pandas\n# Since we already have the data loaded, we can use pandas for aggregations\n\ndf['date'] = pd.to_datetime(df['date'])\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\n\nmonthly_agg_df = df.groupby(['year', 'month', 'utm_tile']).agg({\n    'parcel_id': ['count', 'nunique'],\n    'ndvi': ['mean', 'min', 'max'],\n    'evi': 'mean',\n    'cloud_cover': 'mean'\n}).round(4)\n\n# Flatten column names\nmonthly_agg_df.columns = [\n    'observations', 'unique_parcels', 'avg_ndvi', 'min_ndvi', 'max_ndvi', \n    'avg_evi', 'avg_cloud_cover'\n]\nmonthly_agg_df = monthly_agg_df.reset_index()\n\nprint(\"Monthly Aggregations by UTM Tile:\")\nprint(monthly_agg_df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data quality issues\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for outliers (values outside reasonable ranges)\n",
    "print(\"\\nPotential outliers:\")\n",
    "print(f\"NDVI < -1 or > 1: {((df['ndvi'] < -1) | (df['ndvi'] > 1)).sum()}\")\n",
    "print(f\"EVI < -1 or > 1: {((df['evi'] < -1) | (df['evi'] > 1)).sum()}\")\n",
    "print(f\"Cloud cover < 0 or > 100: {((df['cloud_cover'] < 0) | (df['cloud_cover'] > 100)).sum()}\")\n",
    "\n",
    "# Check observation counts per parcel\n",
    "obs_counts = df.groupby('parcel_id').size()\n",
    "print(f\"\\nObservations per parcel:\")\n",
    "print(f\"Min: {obs_counts.min()}\")\n",
    "print(f\"Max: {obs_counts.max()}\")\n",
    "print(f\"Mean: {obs_counts.mean():.1f}\")\n",
    "print(f\"Parcels with < 10 observations: {(obs_counts < 10).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ANALYSIS SUMMARY ===\")\n",
    "print(f\"📊 Dataset: {len(df):,} observations across {df['parcel_id'].nunique():,} parcels\")\n",
    "print(f\"📅 Time period: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"🗺️  UTM tiles: {', '.join(df['utm_tile'].unique())}\")\n",
    "print(f\"🌱 Average NDVI: {df['ndvi'].mean():.3f} (± {df['ndvi'].std():.3f})\")\n",
    "print(f\"☁️  Average cloud cover: {df['cloud_cover'].mean():.1f}%\")\n",
    "print(f\"📈 NDVI range: {df['ndvi'].min():.3f} to {df['ndvi'].max():.3f}\")\n",
    "\n",
    "# Key findings\n",
    "print(\"\\n=== KEY FINDINGS ===\")\n",
    "print(\"• Vegetation indices show seasonal patterns with growth from winter to spring\")\n",
    "print(\"• Strong positive correlation between NDVI, EVI, and SAVI (as expected)\")\n",
    "print(\"• Cloud cover varies significantly and may impact data quality\")\n",
    "print(\"• UTM tiles show some differences in vegetation characteristics\")\n",
    "print(\"• Data quality is generally good with consistent observations per parcel\")\n",
    "\n",
    "# Clean up\n",
    "conn.close()\n",
    "print(\"\\n✅ Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}