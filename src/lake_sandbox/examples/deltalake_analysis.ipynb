{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeltaLake Data Analysis with DuckDB\n",
    "\n",
    "This notebook demonstrates how to analyze the timeseries data stored in DeltaLake format using DuckDB and create visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DeltaLake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DuckDB and install delta extension\n",
    "conn = duckdb.connect()\n",
    "conn.execute(\"INSTALL delta\")\n",
    "conn.execute(\"LOAD delta\")\n",
    "\n",
    "print(\"Connected to DuckDB with Delta extension loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query DeltaLake Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define path to delta tables\ndelta_dir = \"../../../output/timeseries-delta\"\ndelta_path = Path(delta_dir).absolute()\n\nprint(f\"Delta directory: {delta_path}\")\nprint(f\"Directory exists: {delta_path.exists()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Query all parcel data from DeltaLake tables\n# Note: We need to query each chunk individually since wildcard patterns don't work with delta_scan\n\n# Find all parcel chunk directories\nchunk_dirs = list(delta_path.glob(\"parcel_chunk=*\"))\nprint(f\"Found {len(chunk_dirs)} parcel chunks to query\")\n\n# Query each chunk and combine\ndataframes = []\nfor chunk_dir in sorted(chunk_dirs):\n    try:\n        query = f\"\"\"\n        SELECT \n            parcel_id,\n            date,\n            utm_tile,\n            ndvi,\n            evi,\n            savi,\n            cloud_cover,\n            observation_quality\n        FROM delta_scan('{chunk_dir}')\n        \"\"\"\n        chunk_df = conn.execute(query).df()\n        if not chunk_df.empty:\n            dataframes.append(chunk_df)\n            print(f\"Loaded {len(chunk_df):,} records from {chunk_dir.name}\")\n    except Exception as e:\n        print(f\"Warning: Failed to read {chunk_dir.name}: {e}\")\n        continue\n\n# Combine all dataframes\ndf = pd.concat(dataframes, ignore_index=True)\ndf = df.sort_values(['parcel_id', 'date']).reset_index(drop=True)\n\nprint(f\"Total loaded: {len(df):,} observations for {df['parcel_id'].nunique():,} parcels\")\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Total observations: {len(df):,}\")\n",
    "print(f\"Unique parcels: {df['parcel_id'].nunique():,}\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"UTM tiles: {df['utm_tile'].unique()}\")\n",
    "print(f\"Observation dates: {df['date'].nunique()}\")\n",
    "\n",
    "# Data types and missing values\n",
    "print(\"\\n=== DATA INFO ===\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"=== STATISTICAL SUMMARY ===\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vegetation Index Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plots for vegetation indices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# NDVI distribution\n",
    "axes[0, 0].hist(df[\"ndvi\"], bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[0, 0].set_title(\"NDVI Distribution\", fontsize=14)\n",
    "axes[0, 0].set_xlabel(\"NDVI\")\n",
    "axes[0, 0].set_ylabel(\"Frequency\")\n",
    "axes[0, 0].axvline(df[\"ndvi\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"ndvi\"].mean():.3f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# EVI distribution\n",
    "axes[0, 1].hist(df[\"evi\"], bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0, 1].set_title(\"EVI Distribution\", fontsize=14)\n",
    "axes[0, 1].set_xlabel(\"EVI\")\n",
    "axes[0, 1].set_ylabel(\"Frequency\")\n",
    "axes[0, 1].axvline(df[\"evi\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"evi\"].mean():.3f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# SAVI distribution\n",
    "axes[1, 0].hist(df[\"savi\"], bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "axes[1, 0].set_title(\"SAVI Distribution\", fontsize=14)\n",
    "axes[1, 0].set_xlabel(\"SAVI\")\n",
    "axes[1, 0].set_ylabel(\"Frequency\")\n",
    "axes[1, 0].axvline(df[\"savi\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"savi\"].mean():.3f}')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Cloud cover distribution\n",
    "axes[1, 1].hist(df[\"cloud_cover\"], bins=30, alpha=0.7, color='gray', edgecolor='black')\n",
    "axes[1, 1].set_title(\"Cloud Cover Distribution\", fontsize=14)\n",
    "axes[1, 1].set_xlabel(\"Cloud Cover (%)\")\n",
    "axes[1, 1].set_ylabel(\"Frequency\")\n",
    "axes[1, 1].axvline(df[\"cloud_cover\"].mean(), color='red', linestyle='--', label=f'Mean: {df[\"cloud_cover\"].mean():.1f}%')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_cols = [\"ndvi\", \"evi\", \"savi\", \"cloud_cover\", \"observation_quality\"]\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title(\"Correlation Matrix: Vegetation Indices and Environmental Factors\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Sample a few parcels for time series visualization\n",
    "sample_parcels = df['parcel_id'].unique()[:15]\n",
    "sample_data = df[df['parcel_id'].isin(sample_parcels)]\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for i, parcel_id in enumerate(sample_parcels):\n",
    "    parcel_data = sample_data[sample_data['parcel_id'] == parcel_id].sort_values('date')\n",
    "    plt.plot(parcel_data['date'], parcel_data['ndvi'], \n",
    "             marker='o', markersize=4, alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.title(f\"NDVI Time Series for {len(sample_parcels)} Sample Parcels\", fontsize=16)\n",
    "plt.xlabel(\"Date\", fontsize=12)\n",
    "plt.ylabel(\"NDVI\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add month information\n",
    "df['month'] = df['date'].dt.month\n",
    "df['month_name'] = df['date'].dt.strftime('%B')\n",
    "\n",
    "# Calculate monthly averages\n",
    "monthly_stats = df.groupby(['month', 'month_name']).agg({\n",
    "    'ndvi': ['mean', 'std'],\n",
    "    'evi': ['mean', 'std'],\n",
    "    'savi': ['mean', 'std'],\n",
    "    'cloud_cover': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "print(\"Monthly Statistics:\")\n",
    "print(monthly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot monthly trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "monthly_means = df.groupby('month_name')[['ndvi', 'evi', 'savi', 'cloud_cover']].mean()\n",
    "months_order = df.sort_values('month')['month_name'].unique()\n",
    "monthly_means = monthly_means.reindex(months_order)\n",
    "\n",
    "# NDVI trend\n",
    "axes[0, 0].plot(months_order, monthly_means['ndvi'], marker='o', linewidth=3, markersize=8, color='green')\n",
    "axes[0, 0].set_title(\"Monthly Average NDVI\", fontsize=14)\n",
    "axes[0, 0].set_ylabel(\"NDVI\")\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# EVI trend\n",
    "axes[0, 1].plot(months_order, monthly_means['evi'], marker='o', linewidth=3, markersize=8, color='blue')\n",
    "axes[0, 1].set_title(\"Monthly Average EVI\", fontsize=14)\n",
    "axes[0, 1].set_ylabel(\"EVI\")\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# SAVI trend\n",
    "axes[1, 0].plot(months_order, monthly_means['savi'], marker='o', linewidth=3, markersize=8, color='orange')\n",
    "axes[1, 0].set_title(\"Monthly Average SAVI\", fontsize=14)\n",
    "axes[1, 0].set_ylabel(\"SAVI\")\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Cloud cover trend\n",
    "axes[1, 1].plot(months_order, monthly_means['cloud_cover'], marker='o', linewidth=3, markersize=8, color='gray')\n",
    "axes[1, 1].set_title(\"Monthly Average Cloud Cover\", fontsize=14)\n",
    "axes[1, 1].set_ylabel(\"Cloud Cover (%)\")\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTM Tile Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare vegetation indices between UTM tiles\n",
    "tile_comparison = df.groupby('utm_tile').agg({\n",
    "    'ndvi': ['mean', 'std', 'count'],\n",
    "    'evi': ['mean', 'std'],\n",
    "    'savi': ['mean', 'std'],\n",
    "    'cloud_cover': ['mean', 'std'],\n",
    "    'parcel_id': 'nunique'\n",
    "}).round(4)\n",
    "\n",
    "print(\"UTM Tile Comparison:\")\n",
    "print(tile_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots comparing tiles\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# NDVI by tile\n",
    "df.boxplot(column='ndvi', by='utm_tile', ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"NDVI Distribution by UTM Tile\")\n",
    "axes[0, 0].set_xlabel(\"UTM Tile\")\n",
    "axes[0, 0].set_ylabel(\"NDVI\")\n",
    "\n",
    "# EVI by tile\n",
    "df.boxplot(column='evi', by='utm_tile', ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"EVI Distribution by UTM Tile\")\n",
    "axes[0, 1].set_xlabel(\"UTM Tile\")\n",
    "axes[0, 1].set_ylabel(\"EVI\")\n",
    "\n",
    "# Cloud cover by tile\n",
    "df.boxplot(column='cloud_cover', by='utm_tile', ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Cloud Cover Distribution by UTM Tile\")\n",
    "axes[1, 0].set_xlabel(\"UTM Tile\")\n",
    "axes[1, 0].set_ylabel(\"Cloud Cover (%)\")\n",
    "\n",
    "# Observation quality by tile\n",
    "df.boxplot(column='observation_quality', by='utm_tile', ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Observation Quality by UTM Tile\")\n",
    "axes[1, 1].set_xlabel(\"UTM Tile\")\n",
    "axes[1, 1].set_ylabel(\"Observation Quality\")\n",
    "\n",
    "plt.suptitle(\"\")  # Remove default title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Queries with DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Find parcels with highest NDVI growth\n# Note: Using the already loaded dataframe instead of direct DuckDB query for simplicity\n\n# Calculate NDVI growth per parcel\nparcel_stats = df.groupby(['parcel_id', 'utm_tile']).agg({\n    'ndvi': ['min', 'max', 'mean', 'count']\n}).round(4)\n\n# Flatten column names\nparcel_stats.columns = ['min_ndvi', 'max_ndvi', 'avg_ndvi', 'observations']\nparcel_stats = parcel_stats.reset_index()\n\n# Calculate NDVI growth\nparcel_stats['ndvi_growth'] = parcel_stats['max_ndvi'] - parcel_stats['min_ndvi']\n\n# Filter parcels with at least 10 observations and sort by growth\nhigh_growth = parcel_stats[parcel_stats['observations'] >= 10].sort_values('ndvi_growth', ascending=False).head(10)\n\nprint(\"Top 10 Parcels with Highest NDVI Growth:\")\nprint(high_growth)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Monthly aggregations using pandas\n# Since we already have the data loaded, we can use pandas for aggregations\n\ndf['date'] = pd.to_datetime(df['date'])\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\n\nmonthly_agg_df = df.groupby(['year', 'month', 'utm_tile']).agg({\n    'parcel_id': ['count', 'nunique'],\n    'ndvi': ['mean', 'min', 'max'],\n    'evi': 'mean',\n    'cloud_cover': 'mean'\n}).round(4)\n\n# Flatten column names\nmonthly_agg_df.columns = [\n    'observations', 'unique_parcels', 'avg_ndvi', 'min_ndvi', 'max_ndvi', \n    'avg_evi', 'avg_cloud_cover'\n]\nmonthly_agg_df = monthly_agg_df.reset_index()\n\nprint(\"Monthly Aggregations by UTM Tile:\")\nprint(monthly_agg_df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data quality issues\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for outliers (values outside reasonable ranges)\n",
    "print(\"\\nPotential outliers:\")\n",
    "print(f\"NDVI < -1 or > 1: {((df['ndvi'] < -1) | (df['ndvi'] > 1)).sum()}\")\n",
    "print(f\"EVI < -1 or > 1: {((df['evi'] < -1) | (df['evi'] > 1)).sum()}\")\n",
    "print(f\"Cloud cover < 0 or > 100: {((df['cloud_cover'] < 0) | (df['cloud_cover'] > 100)).sum()}\")\n",
    "\n",
    "# Check observation counts per parcel\n",
    "obs_counts = df.groupby('parcel_id').size()\n",
    "print(f\"\\nObservations per parcel:\")\n",
    "print(f\"Min: {obs_counts.min()}\")\n",
    "print(f\"Max: {obs_counts.max()}\")\n",
    "print(f\"Mean: {obs_counts.mean():.1f}\")\n",
    "print(f\"Parcels with < 10 observations: {(obs_counts < 10).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ANALYSIS SUMMARY ===\")\n",
    "print(f\"ðŸ“Š Dataset: {len(df):,} observations across {df['parcel_id'].nunique():,} parcels\")\n",
    "print(f\"ðŸ“… Time period: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"ðŸ—ºï¸  UTM tiles: {', '.join(df['utm_tile'].unique())}\")\n",
    "print(f\"ðŸŒ± Average NDVI: {df['ndvi'].mean():.3f} (Â± {df['ndvi'].std():.3f})\")\n",
    "print(f\"â˜ï¸  Average cloud cover: {df['cloud_cover'].mean():.1f}%\")\n",
    "print(f\"ðŸ“ˆ NDVI range: {df['ndvi'].min():.3f} to {df['ndvi'].max():.3f}\")\n",
    "\n",
    "# Key findings\n",
    "print(\"\\n=== KEY FINDINGS ===\")\n",
    "print(\"â€¢ Vegetation indices show seasonal patterns with growth from winter to spring\")\n",
    "print(\"â€¢ Strong positive correlation between NDVI, EVI, and SAVI (as expected)\")\n",
    "print(\"â€¢ Cloud cover varies significantly and may impact data quality\")\n",
    "print(\"â€¢ UTM tiles show some differences in vegetation characteristics\")\n",
    "print(\"â€¢ Data quality is generally good with consistent observations per parcel\")\n",
    "\n",
    "# Clean up\n",
    "conn.close()\n",
    "print(\"\\nâœ… Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}