# DeltaLake Analysis Examples

This directory contains examples demonstrating how to analyze the timeseries data generated by the lake-sandbox pipeline
using DuckDB and create visualizations.

## Overview

After running the lake-sandbox pipeline, your data will be stored in DeltaLake format at `output/timeseries-delta/`.
These examples show how to:

- Connect to DeltaLake tables using DuckDB
- Query and analyze vegetation timeseries data
- Create various visualizations and charts
- Perform statistical analysis and data quality assessment

## Files

### ðŸ“„ `duckdb_analysis.py`

A complete Python script that demonstrates:

- Connecting to DeltaLake data with DuckDB
- Querying parcel timeseries data
- Creating multiple visualizations:
    - NDVI timeseries plots
    - Vegetation index distributions
    - Correlation heatmaps
    - UTM tile comparisons
    - Monthly trend analysis

### ðŸ““ `deltalake_analysis.ipynb`

An interactive Jupyter notebook with the same analysis as the Python script, plus:

- Step-by-step explanations
- Interactive plots
- Data quality assessment
- Advanced DuckDB queries
- Summary findings

## Prerequisites

Make sure you have these dependencies installed:

```bash
uv add duckdb pandas matplotlib seaborn jupyter
```

## Usage

### Option 1: Using the CLI (Recommended)

```bash
# Basic analysis with default settings
uv run lake-sandbox analyze

# Specify custom paths and options
uv run lake-sandbox analyze --delta-dir output/timeseries-delta --output-dir plots --sample-parcels 15

# Show plots interactively (requires display)
uv run lake-sandbox analyze --show-plots
```

### Option 2: Run the Python Script Directly

```bash
cd src/lake_sandbox/examples/
python duckdb_analysis.py
```

This will:

1. Connect to your DeltaLake data
2. Generate several visualization files:
    - `ndvi_timeseries.png`
    - `vegetation_distributions.png`
    - `correlation_heatmap.png`
    - `utm_tile_comparison.png`
    - `monthly_trends.png`
3. Print statistical summaries to the console

### Option 2: Use the Jupyter Notebook

```bash
cd examples/
jupyter notebook deltalake_analysis.ipynb
```

This provides an interactive environment where you can:

- Run cells individually
- Modify queries and visualizations
- Explore the data step by step
- Add your own analysis

## Example Queries

### Basic Data Loading

```sql
SELECT 
    parcel_id,
    date,
    utm_tile,
    ndvi,
    evi,
    savi,
    cloud_cover
FROM delta_scan('./output/timeseries-delta/parcel_chunk=*')
ORDER BY parcel_id, date
```

### Monthly Aggregations

```sql
SELECT 
    EXTRACT(MONTH FROM date) as month,
    utm_tile,
    COUNT(*) as observations,
    AVG(ndvi) as avg_ndvi,
    AVG(cloud_cover) as avg_cloud_cover
FROM delta_scan('./output/timeseries-delta/parcel_chunk=*')
GROUP BY EXTRACT(MONTH FROM date), utm_tile
ORDER BY month, utm_tile
```

### Find High-Growth Parcels

```sql
WITH parcel_stats AS (
    SELECT 
        parcel_id,
        MIN(ndvi) as min_ndvi,
        MAX(ndvi) as max_ndvi,
        MAX(ndvi) - MIN(ndvi) as ndvi_growth
    FROM delta_scan('./output/timeseries-delta/parcel_chunk=*')
    GROUP BY parcel_id
)
SELECT *
FROM parcel_stats
ORDER BY ndvi_growth DESC
LIMIT 10
```

## Expected Outputs

### Statistical Summary

- Total parcels: ~500,000
- Total observations: ~8,000,000
- Date range: 2024-01-01 to 2024-04-15 (16 dates)
- UTM tiles: 32TNR, 32TPR
- Average NDVI: ~0.3-0.7 (varies by season)

### Visualizations

1. **NDVI Timeseries**: Shows vegetation growth patterns over time for sample parcels
2. **Distribution Plots**: Histograms of NDVI, EVI, SAVI, and cloud cover values
3. **Correlation Heatmap**: Relationships between vegetation indices and environmental factors
4. **UTM Tile Comparison**: Box plots comparing vegetation indices between tiles
5. **Monthly Trends**: Seasonal patterns in vegetation indices

## Key Insights

The analysis typically reveals:

- **Seasonal Growth**: Vegetation indices increase from winter (January) to spring (April)
- **Strong Correlations**: NDVI, EVI, and SAVI are highly correlated (r > 0.9)
- **Cloud Impact**: Higher cloud cover generally correlates with lower observation quality
- **Spatial Variation**: Different UTM tiles may show varying vegetation characteristics
- **Data Quality**: Most parcels have consistent observations across all dates

## Customization

You can easily modify the examples to:

- **Filter data**: Add WHERE clauses to focus on specific parcels, dates, or tiles
- **Add metrics**: Calculate additional vegetation indices or statistics
- **Change visualizations**: Modify plot types, colors, or layouts
- **Export results**: Save analysis results to CSV, Parquet, or other formats

### Example Customizations

```python
# Filter to specific UTM tile
query = f"""
SELECT * FROM delta_scan('{delta_path}/parcel_chunk=*')
WHERE utm_tile = '32TNR'
"""

# Calculate custom vegetation index
df['custom_vi'] = (df['ndvi'] + df['evi']) / 2

# Export results
df.to_csv('analysis_results.csv', index=False)
```

## Performance Tips

- **Chunk Queries**: For large datasets, process chunks individually
- **Use Projections**: Only select columns you need
- **Add Filters**: Use WHERE clauses to limit data early
- **Parallel Processing**: DuckDB automatically parallelizes queries

## Troubleshooting

### Common Issues

1. **"Table not found"**: Ensure the DeltaLake data exists at `./output/timeseries-delta/`
2. **"Delta extension not found"**: Install DuckDB delta extension: `pip install duckdb[delta]`
3. **Memory issues**: Process data in smaller chunks or increase available memory
4. **Import errors**: Install missing dependencies: `pip install matplotlib seaborn`

### Performance Issues

If queries are slow:

- Check available memory
- Reduce the number of parcels being analyzed
- Use sampling for initial exploration
- Consider using DuckDB's parallelization settings

## Next Steps

After running these examples, you might want to:

1. **Advanced Analytics**: Implement change detection algorithms
2. **Machine Learning**: Train models on the vegetation timeseries
3. **Web Dashboard**: Create interactive dashboards using Streamlit or Dash
4. **Automated Reports**: Schedule regular analysis reports
5. **Real-time Analysis**: Set up streaming analysis for new data

## Support

For questions or issues:

- Check the main lake-sandbox documentation
- Review DuckDB documentation for advanced queries
- Open an issue in the project repository
